{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_models as tfm\n",
    "import keras\n",
    "import time\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable GPU dynamic memory allocation\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = \"my_ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8\"\n",
    "#model_name = \"my_ssd_resnet50_v1_fpn\"\n",
    "model_name = \"my_ssd_resnet50_v1_fpn_exported\"\n",
    "#model_name = \"my_ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8\"\n",
    "#model_name = \"my_ssd_resnet152_v1_fpn_640x640_coco17_tpu-8\"\n",
    "#model_name = \"my_ssd_resnet101_v1_fpn_640x640_coco17_tpu-8\"\n",
    "\n",
    "images_path = f\"TensorFlow/workspace/training_demo/images\"\n",
    "model_path = f\"TensorFlow/workspace/training_demo/models/{model_name}\"\n",
    "exported_model_path = f\"TensorFlow/workspace/training_demo/exported-models/\"\n",
    "\n",
    "ckpt_dict = {\"my_ssd_resnet50_v1_fpn\":'/ckpt-31',\n",
    "                    \"my_ssd_resnet101_v1_fpn_640x640_coco17_tpu-8\":\"/ckpt-28\",\n",
    "                    \"my_ssd_resnet152_v1_fpn_640x640_coco17_tpu-8\":\"/ckpt-26\",\n",
    "                    \"my_ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8\":\"/ckpt-26\",\n",
    "                    \"my_ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8\": \"/ckpt-51\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTO = tf.data.AUTOTUNE  # Used to dynamically adjust parallelism.\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Comes from Table 4 and \"Training setup\" section.\n",
    "TEMPERATURE = 10  # Used to soften the logits before they go to softmax.\n",
    "INIT_LR = 0.003  # Initial learning rate that will be decayed over the training period.\n",
    "WEIGHT_DECAY = 0.001  # Used for regularization.\n",
    "CLIP_THRESHOLD = 1.0  # Used for clipping the gradients by L2-norm.\n",
    "\n",
    "# We will first resize the training images to a bigger size and then we will take\n",
    "# random crops of a lower size.\n",
    "BIGGER = 160\n",
    "RESIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 409 files belonging to 1 classes.\n",
      "Using 328 files for training.\n",
      "Found 409 files belonging to 1 classes.\n",
      "Using 81 files for validation.\n",
      "Found 22 files belonging to 1 classes.\n",
      "Number of training examples: 11.\n",
      "Number of validation examples: 3.\n",
      "Number of test examples: 1.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    images_path + \"/train\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",  \n",
    "    validation_split=0.2,  \n",
    "    subset=\"training\",\n",
    "    seed=1337,  \n",
    "    image_size=(640, 640),  \n",
    "    batch_size=4 \n",
    ")\n",
    "\n",
    "validation_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    images_path + \"/train\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",  \n",
    "    validation_split=0.2,  \n",
    "    subset=\"validation\",\n",
    "    seed=1337, \n",
    "    image_size=(640, 640),  \n",
    "    batch_size=4 \n",
    ")\n",
    "\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    images_path + \"/test\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",  \n",
    "    seed=1337,  \n",
    "    image_size=(640, 640),  \n",
    "    batch_size=32  \n",
    ")\n",
    "print(f\"Number of training examples: {train_ds.cardinality()}.\")\n",
    "print(\n",
    "    f\"Number of validation examples: {validation_ds.cardinality()}.\"\n",
    ")\n",
    "print(f\"Number of test examples: {test_ds.cardinality()}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Teacher Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    }
   ],
   "source": [
    "teacher_model = keras.models.load_model(exported_model_path + f\"{model_name}_keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Student model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mobilenet():\n",
    "    mobilenet = keras.applications.MobileNet(\n",
    "        input_shape=(640, 640, 3),\n",
    "        include_top=True,\n",
    "        weights=None,\n",
    "        classes=100  # Adjust this according to your needs\n",
    "    )\n",
    "    return mobilenet\n",
    "\n",
    "student_model = get_mobilenet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Distiller(tf.keras.Model):\n",
    "    def __init__(self, student, teacher):\n",
    "        super().__init__()\n",
    "        self.student = student\n",
    "        self.teacher = teacher\n",
    "        self.loss_tracker = keras.metrics.Mean(name=\"distillation_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        metrics = super().metrics\n",
    "        metrics.append(self.loss_tracker)\n",
    "        return metrics\n",
    "\n",
    "    def compile(self, optimizer, metrics, distillation_loss_fn, temperature):\n",
    "        super().compile(optimizer=optimizer, metrics=metrics)\n",
    "        self.distillation_loss_fn = distillation_loss_fn\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def preprocess_for_teacher(self, x):\n",
    "        x_resized = tf.image.resize(x, (640, 640))\n",
    "        x_cast = tf.cast(x_resized, dtype=tf.uint8)\n",
    "        return x_cast\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, inputs, training=False):\n",
    "        student_predictions = self.student(inputs, training=training)\n",
    "        return student_predictions\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "        x_teacher = self.preprocess_for_teacher(x)\n",
    "\n",
    "        # Debugging: wydrukuj kształty\n",
    "        tf.print(\"x_teacher shape:\", tf.shape(x_teacher))\n",
    "\n",
    "        # Forward pass nauczyciela\n",
    "        teacher_predictions = self.teacher(x_teacher)\n",
    "        teacher_class_predictions = teacher_predictions['detection_classes']  # Wyodrębnij odpowiednie predykcje\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass ucznia\n",
    "            student_predictions = self.student(x, training=True)\n",
    "\n",
    "            # Obliczanie straty\n",
    "            distillation_loss = self.distillation_loss_fn(\n",
    "                tf.nn.softmax(teacher_class_predictions / self.temperature, axis=-1),\n",
    "                tf.nn.softmax(student_predictions / self.temperature, axis=-1),\n",
    "            )\n",
    "\n",
    "        # Obliczanie gradientów\n",
    "        trainable_vars = self.student.trainable_variables\n",
    "        gradients = tape.gradient(distillation_loss, trainable_vars)\n",
    "\n",
    "        # Aktualizacja wag\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "\n",
    "        # Raportowanie postępów\n",
    "        self.loss_tracker.update_state(distillation_loss)\n",
    "        return {\"distillation_loss\": self.loss_tracker.result()}\n",
    "\n",
    "    @tf.function\n",
    "    def test_step(self, data):\n",
    "        x, y = data\n",
    "        x_teacher = self.preprocess_for_teacher(x)\n",
    "\n",
    "        # Forward passes\n",
    "        teacher_predictions = self.teacher(tf.expand_dims(x_teacher, axis=0))\n",
    "        student_predictions = self.student(x, training=False)\n",
    "\n",
    "        # Obliczanie straty\n",
    "        distillation_loss = self.distillation_loss_fn(\n",
    "            tf.nn.softmax(teacher_predictions / self.temperature, axis=-1),\n",
    "            tf.nn.softmax(student_predictions / self.temperature, axis=-1),\n",
    "        )\n",
    "\n",
    "        # Raportowanie postępów\n",
    "        self.loss_tracker.update_state(distillation_loss)\n",
    "        self.compiled_metrics.update_state(y, student_predictions)\n",
    "        results = {m.name: m.result() for m in self.metrics}\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WarmUpCosine(keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(\n",
    "        self, learning_rate_base, total_steps, warmup_learning_rate, warmup_steps\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.learning_rate_base = learning_rate_base\n",
    "        self.total_steps = total_steps\n",
    "        self.warmup_learning_rate = warmup_learning_rate\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.pi = tf.constant(np.pi)\n",
    "\n",
    "    def __call__(self, step):\n",
    "        if self.total_steps < self.warmup_steps:\n",
    "            raise ValueError(\"Total_steps must be larger or equal to warmup_steps.\")\n",
    "\n",
    "        cos_annealed_lr = tf.cos(\n",
    "            self.pi\n",
    "            * (tf.cast(step, tf.float32) - self.warmup_steps)\n",
    "            / float(self.total_steps - self.warmup_steps)\n",
    "        )\n",
    "        learning_rate = 0.5 * self.learning_rate_base * (1 + cos_annealed_lr)\n",
    "\n",
    "        if self.warmup_steps > 0:\n",
    "            if self.learning_rate_base < self.warmup_learning_rate:\n",
    "                raise ValueError(\n",
    "                    \"Learning_rate_base must be larger or equal to \"\n",
    "                    \"warmup_learning_rate.\"\n",
    "                )\n",
    "            slope = (\n",
    "                self.learning_rate_base - self.warmup_learning_rate\n",
    "            ) / self.warmup_steps\n",
    "            warmup_rate = slope * tf.cast(step, tf.float32) + self.warmup_learning_rate\n",
    "            learning_rate = tf.where(\n",
    "                step < self.warmup_steps, warmup_rate, learning_rate\n",
    "            )\n",
    "        return tf.where(\n",
    "            step > self.total_steps, 0.0, learning_rate, name=\"learning_rate\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16451/4116323539.py:18: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "ARTIFICIAL_EPOCHS = 1000\n",
    "ARTIFICIAL_BATCH_SIZE = 512\n",
    "DATASET_NUM_TRAIN_EXAMPLES = 1020\n",
    "TOTAL_STEPS = int(\n",
    "    DATASET_NUM_TRAIN_EXAMPLES / ARTIFICIAL_BATCH_SIZE * ARTIFICIAL_EPOCHS\n",
    ")\n",
    "scheduled_lrs = WarmUpCosine(\n",
    "    learning_rate_base=INIT_LR,\n",
    "    total_steps=TOTAL_STEPS,\n",
    "    warmup_learning_rate=0.0,\n",
    "    warmup_steps=1500,\n",
    ")\n",
    "\n",
    "lrs = [scheduled_lrs(step) for step in range(TOTAL_STEPS)]\n",
    "plt.plot(lrs)\n",
    "plt.xlabel(\"Step\", fontsize=14)\n",
    "plt.ylabel(\"LR\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"/home/hapek-wsl/anaconda3/envs/tf_od/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/tmp/ipykernel_16451/2914540077.py\", line 38, in train_step  *\n        teacher_predictions = self.teacher(x_teacher)\n\n    TypeError: Binding inputs to tf.function failed due to `Can not cast TensorSpec(shape=(None, 640, 640, 3), dtype=tf.uint8, name='input_tensor') to TensorSpec(shape=(1, None, None, 3), dtype=tf.uint8, name='input_tensor')`. Received args: (<tf.Tensor 'Cast:0' shape=(None, 640, 640, 3) dtype=uint8>,) and kwargs: {} for signature: (input_tensor: TensorSpec(shape=(1, None, None, 3), dtype=tf.uint8, name='input_tensor')).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 16\u001b[0m\n\u001b[1;32m      8\u001b[0m distiller \u001b[38;5;241m=\u001b[39m Distiller(student\u001b[38;5;241m=\u001b[39mstudent_model, teacher\u001b[38;5;241m=\u001b[39mteacher_model)\n\u001b[1;32m      9\u001b[0m distiller\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m     10\u001b[0m     optimizer,\n\u001b[1;32m     11\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[keras\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mSparseCategoricalAccuracy()],\n\u001b[1;32m     12\u001b[0m     distillation_loss_fn\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mKLDivergence(),\n\u001b[1;32m     13\u001b[0m     temperature\u001b[38;5;241m=\u001b[39mTEMPERATURE,\n\u001b[1;32m     14\u001b[0m )\n\u001b[0;32m---> 16\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mdistiller\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mceil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATASET_NUM_TRAIN_EXAMPLES\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# This should be at least 1000.\u001b[39;49;00m\n\u001b[1;32m     21\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m student \u001b[38;5;241m=\u001b[39m distiller\u001b[38;5;241m.\u001b[39mstudent\n\u001b[1;32m     24\u001b[0m student_model\u001b[38;5;241m.\u001b[39mcompile(metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/tf_od/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileu28y1mlm.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filexw9b1plz.py:13\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     11\u001b[0m x_teacher \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mpreprocess_for_teacher, (ag__\u001b[38;5;241m.\u001b[39mld(x),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     12\u001b[0m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mprint, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_teacher shape:\u001b[39m\u001b[38;5;124m'\u001b[39m, ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mshape, (ag__\u001b[38;5;241m.\u001b[39mld(x_teacher),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 13\u001b[0m teacher_predictions \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mteacher, (ag__\u001b[38;5;241m.\u001b[39mld(x_teacher),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     14\u001b[0m teacher_class_predictions \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(teacher_predictions)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdetection_classes\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/home/hapek-wsl/anaconda3/envs/tf_od/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/tmp/ipykernel_16451/2914540077.py\", line 38, in train_step  *\n        teacher_predictions = self.teacher(x_teacher)\n\n    TypeError: Binding inputs to tf.function failed due to `Can not cast TensorSpec(shape=(None, 640, 640, 3), dtype=tf.uint8, name='input_tensor') to TensorSpec(shape=(1, None, None, 3), dtype=tf.uint8, name='input_tensor')`. Received args: (<tf.Tensor 'Cast:0' shape=(None, 640, 640, 3) dtype=uint8>,) and kwargs: {} for signature: (input_tensor: TensorSpec(shape=(1, None, None, 3), dtype=tf.uint8, name='input_tensor')).\n"
     ]
    }
   ],
   "source": [
    "optimizer = tfa.optimizers.AdamW(\n",
    "    weight_decay=WEIGHT_DECAY, learning_rate=scheduled_lrs, clipnorm=CLIP_THRESHOLD\n",
    ")\n",
    "\n",
    "student_model = get_mobilenet()\n",
    "\n",
    "# Kompilacja i trening modelu\n",
    "distiller = Distiller(student=student_model, teacher=teacher_model)\n",
    "distiller.compile(\n",
    "    optimizer,\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "    distillation_loss_fn=keras.losses.KLDivergence(),\n",
    "    temperature=TEMPERATURE,\n",
    ")\n",
    "\n",
    "history = distiller.fit(\n",
    "    train_ds,\n",
    "    steps_per_epoch=int(np.ceil(DATASET_NUM_TRAIN_EXAMPLES / BATCH_SIZE)),\n",
    "    validation_data=validation_ds,\n",
    "    epochs=30,  # This should be at least 1000.\n",
    ")\n",
    "\n",
    "student = distiller.student\n",
    "student_model.compile(metrics=[\"accuracy\"])\n",
    "_, top1_accuracy = student.evaluate(test_ds)\n",
    "print(f\"Top-1 accuracy on the test set: {round(top1_accuracy * 100, 2)}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_od",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
