{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-21 12:38:16.775566: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-21 12:38:16.775620: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-21 12:38:16.786697: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-21 12:38:16.866025: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-21 12:38:18.539876: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from platesdetection import ModelLoader\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"my_ssd_resnet50_v1_fpn\"\n",
    "#model_name = \"my_ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8\"\n",
    "#model_name = \"my_ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8\"\n",
    "#model_name = \"my_ssd_resnet152_v1_fpn_640x640_coco17_tpu-8\"\n",
    "#model_name = \"my_ssd_resnet101_v1_fpn_640x640_coco17_tpu-8\"\n",
    "#model_name = \"my_ssd_resnet50_v1_fpn_exported\"\n",
    "\n",
    "images_path = f\"TensorFlow/workspace/training_demo/images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Loading TF2 Checkpoint]\n",
      "Loading model - my_ssd_resnet50_v1_fpn... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-21 12:38:26.890288: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-21 12:38:26.894499: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-21 12:38:26.894597: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-21 12:38:26.925274: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-21 12:38:26.925431: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-21 12:38:26.925482: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-21 12:38:27.088697: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-21 12:38:27.088832: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-21 12:38:27.088846: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-05-21 12:38:27.088907: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-21 12:38:27.088930: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2863 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has been loaded - 0.32s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loader = ModelLoader()\n",
    "teacher_model = loader.load_model(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 409 files belonging to 1 classes.\n",
      "Using 328 files for training.\n",
      "Found 22 files belonging to 1 classes.\n",
      "Using 4 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    images_path + \"/train\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    validation_split=0.2, \n",
    "    subset=\"training\",\n",
    "    seed=1337, \n",
    "    image_size=(640, 640),\n",
    "    batch_size=4\n",
    ")\n",
    "\n",
    "val_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    images_path + \"/test\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\", \n",
    "    validation_split=0.2, \n",
    "    subset=\"validation\",\n",
    "    seed=1337, \n",
    "    image_size=(640, 640), \n",
    "    batch_size=4  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def detect_fn(image, detection_model):\n",
    "    \"\"\"Detect objects in image.\"\"\"\n",
    "\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "\n",
    "    return detections\n",
    "\n",
    "def detect_object(image_np, detection_model, model_name):\n",
    "    label_filename = \"label_map.pbtxt\"\n",
    "    path_to_labels = f\"TensorFlow/workspace/training_demo/annotations/{label_filename}\"\n",
    "    category_index = label_map_util.create_category_index_from_labelmap(path_to_labels, use_display_name=True)\n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "\n",
    "    if model_name[-9:] == \"_exported\":\n",
    "        # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
    "        input_tensor = tf.convert_to_tensor(image_np)\n",
    "        # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
    "        input_tensor = input_tensor[tf.newaxis, ...]\n",
    "        detections = detection_model(input_tensor)\n",
    "    else:\n",
    "        detections = detect_fn(input_tensor, detection_model)\n",
    "\n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "    label_id_offset = 1\n",
    "    image_np_with_detections = image_np.copy()\n",
    "\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "            image_np_with_detections,\n",
    "            detections['detection_boxes'],\n",
    "            detections['detection_classes']+label_id_offset,\n",
    "            detections['detection_scores'],\n",
    "            category_index,\n",
    "            use_normalized_coordinates=True,\n",
    "            max_boxes_to_draw=200,\n",
    "            min_score_thresh=.30,\n",
    "            agnostic_mode=False)\n",
    "\n",
    "    return image_np_with_detections, detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mobilenet(num_classes):\n",
    "    model = tf.keras.applications.MobileNetV2(input_shape=[640, 640, 3],\n",
    "                                                   include_top=False,\n",
    "                                                   weights=None,\n",
    "                                                   classes=num_classes)\n",
    "\n",
    "    model.trainable = True\n",
    "    return model\n",
    "\n",
    "\n",
    "def distillation_loss(y_true, y_pred, teacher_preds, alpha=0.1, temperature=3):\n",
    "    student_loss = tf.keras.losses.SparseCategoricalCrossentropy()(y_true, y_pred)\n",
    "    distillation_loss = tf.keras.losses.KLDivergence()(tf.nn.softmax(teacher_preds / temperature),\n",
    "                                                      tf.nn.softmax(y_pred / temperature))\n",
    "    return alpha * student_loss + (1 - alpha) * distillation_loss\n",
    "\n",
    "def train_student_model(teacher_model, student_model, train_data, val_data, epochs=10, learning_rate=0.001):\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    student_model.compile(optimizer=optimizer, loss=distillation_loss)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f'Epoch {epoch+1}/{epochs}')\n",
    "        for images, labels in train_data:\n",
    "            teacher_preds = []\n",
    "            for image in images:\n",
    "                detections = detect_fn(tf.convert_to_tensor(np.expand_dims(np.array(image), 0), dtype=tf.float32), teacher_model)\n",
    "                teacher_preds.append(detections['detection_scores'])\n",
    "\n",
    "            teacher_preds = tf.convert_to_tensor(teacher_preds)\n",
    "            student_model.train_on_batch(images, labels, sample_weight=teacher_preds)\n",
    "\n",
    "        val_loss = 0\n",
    "        for images, labels in val_data:\n",
    "            teacher_preds = []\n",
    "            for image in images:\n",
    "                detections = detect_fn(tf.convert_to_tensor(np.expand_dims(np.array(image), 0), dtype=tf.float32), teacher_model)\n",
    "                teacher_preds.append(detections['detection_scores'])\n",
    "\n",
    "            teacher_preds = tf.convert_to_tensor(teacher_preds)\n",
    "            val_loss += student_model.test_on_batch(images, labels, sample_weight=teacher_preds)\n",
    "\n",
    "        print(f'Validation loss: {val_loss / len(val_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model = create_mobilenet(num_classes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-21 12:39:13.604764: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"/home/hapek-wsl/anaconda3/envs/tf_od/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n\n    TypeError: tf__distillation_loss() missing 1 required positional argument: 'teacher_preds'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_student_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mteacher_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstudent_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 30\u001b[0m, in \u001b[0;36mtrain_student_model\u001b[0;34m(teacher_model, student_model, train_data, val_data, epochs, learning_rate)\u001b[0m\n\u001b[1;32m     27\u001b[0m         teacher_preds\u001b[38;5;241m.\u001b[39mappend(detections[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdetection_scores\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     29\u001b[0m     teacher_preds \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(teacher_preds)\n\u001b[0;32m---> 30\u001b[0m     \u001b[43mstudent_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mteacher_preds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m val_data:\n",
      "File \u001b[0;32m~/anaconda3/envs/tf_od/lib/python3.9/site-packages/keras/src/engine/training.py:2787\u001b[0m, in \u001b[0;36mModel.train_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   2783\u001b[0m     iterator \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39msingle_batch_iterator(\n\u001b[1;32m   2784\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy, x, y, sample_weight, class_weight\n\u001b[1;32m   2785\u001b[0m     )\n\u001b[1;32m   2786\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_train_function()\n\u001b[0;32m-> 2787\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2789\u001b[0m logs \u001b[38;5;241m=\u001b[39m tf_utils\u001b[38;5;241m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[1;32m   2790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict:\n",
      "File \u001b[0;32m~/anaconda3/envs/tf_od/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileink7oyb0.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf_od/lib/python3.9/site-packages/keras/src/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   1380\u001b[0m     run_step \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mfunction(\n\u001b[1;32m   1381\u001b[0m         run_step, jit_compile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, reduce_retracing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1382\u001b[0m     )\n\u001b[1;32m   1383\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iterator)\n\u001b[0;32m-> 1384\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1385\u001b[0m outputs \u001b[38;5;241m=\u001b[39m reduce_per_replica(\n\u001b[1;32m   1386\u001b[0m     outputs,\n\u001b[1;32m   1387\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy,\n\u001b[1;32m   1388\u001b[0m     reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_reduction_method,\n\u001b[1;32m   1389\u001b[0m )\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/anaconda3/envs/tf_od/lib/python3.9/site-packages/keras/src/engine/training.py:1373\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_step\u001b[39m(data):\n\u001b[0;32m-> 1373\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1374\u001b[0m     \u001b[38;5;66;03m# Ensure counter is updated only if `train_step` succeeds.\u001b[39;00m\n\u001b[1;32m   1375\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001b[0;32m~/anaconda3/envs/tf_od/lib/python3.9/site-packages/keras/src/engine/training.py:1151\u001b[0m, in \u001b[0;36mModel.train_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[1;32m   1150\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(x, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 1151\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss(x, y, y_pred, sample_weight)\n\u001b[1;32m   1152\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_target_and_loss(y, loss)\n\u001b[1;32m   1153\u001b[0m \u001b[38;5;66;03m# Run backwards pass.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf_od/lib/python3.9/site-packages/keras/src/engine/training.py:1209\u001b[0m, in \u001b[0;36mModel.compute_loss\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1158\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute the total loss, validate it, and return it.\u001b[39;00m\n\u001b[1;32m   1159\u001b[0m \n\u001b[1;32m   1160\u001b[0m \u001b[38;5;124;03mSubclasses can optionally override this method to provide custom loss\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1206\u001b[0m \u001b[38;5;124;03m  is the case when called by `Model.test_step`).\u001b[39;00m\n\u001b[1;32m   1207\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m x  \u001b[38;5;66;03m# The default implementation does not use `x`.\u001b[39;00m\n\u001b[0;32m-> 1209\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompiled_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregularization_losses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlosses\u001b[49m\n\u001b[1;32m   1211\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf_od/lib/python3.9/site-packages/keras/src/engine/compile_utils.py:277\u001b[0m, in \u001b[0;36mLossesContainer.__call__\u001b[0;34m(self, y_true, y_pred, sample_weight, regularization_losses)\u001b[0m\n\u001b[1;32m    275\u001b[0m y_t, y_p, sw \u001b[38;5;241m=\u001b[39m match_dtype_and_rank(y_t, y_p, sw)\n\u001b[1;32m    276\u001b[0m sw \u001b[38;5;241m=\u001b[39m losses_utils\u001b[38;5;241m.\u001b[39mapply_mask(y_p, sw, losses_utils\u001b[38;5;241m.\u001b[39mget_mask(y_p))\n\u001b[0;32m--> 277\u001b[0m loss_value \u001b[38;5;241m=\u001b[39m \u001b[43mloss_obj\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m total_loss_mean_value \u001b[38;5;241m=\u001b[39m loss_value\n\u001b[1;32m    280\u001b[0m \u001b[38;5;66;03m# Correct for the `Mean` loss metrics counting each replica as a\u001b[39;00m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;66;03m# batch.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf_od/lib/python3.9/site-packages/keras/src/losses.py:143\u001b[0m, in \u001b[0;36mLoss.__call__\u001b[0;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    139\u001b[0m     call_fn \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39m__internal__\u001b[38;5;241m.\u001b[39mautograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall, tf\u001b[38;5;241m.\u001b[39m__internal__\u001b[38;5;241m.\u001b[39mautograph\u001b[38;5;241m.\u001b[39mcontrol_status_ctx()\n\u001b[1;32m    141\u001b[0m     )\n\u001b[0;32m--> 143\u001b[0m losses \u001b[38;5;241m=\u001b[39m call_fn(y_true, y_pred)\n\u001b[1;32m    145\u001b[0m in_mask \u001b[38;5;241m=\u001b[39m losses_utils\u001b[38;5;241m.\u001b[39mget_mask(y_pred)\n\u001b[1;32m    146\u001b[0m out_mask \u001b[38;5;241m=\u001b[39m losses_utils\u001b[38;5;241m.\u001b[39mget_mask(losses)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf_od/lib/python3.9/site-packages/keras/src/losses.py:270\u001b[0m, in \u001b[0;36mLossFunctionWrapper.call\u001b[0;34m(self, y_true, y_pred)\u001b[0m\n\u001b[1;32m    263\u001b[0m     y_pred, y_true \u001b[38;5;241m=\u001b[39m losses_utils\u001b[38;5;241m.\u001b[39msqueeze_or_expand_dimensions(\n\u001b[1;32m    264\u001b[0m         y_pred, y_true\n\u001b[1;32m    265\u001b[0m     )\n\u001b[1;32m    267\u001b[0m ag_fn \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39m__internal__\u001b[38;5;241m.\u001b[39mautograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn, tf\u001b[38;5;241m.\u001b[39m__internal__\u001b[38;5;241m.\u001b[39mautograph\u001b[38;5;241m.\u001b[39mcontrol_status_ctx()\n\u001b[1;32m    269\u001b[0m )\n\u001b[0;32m--> 270\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mag_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/home/hapek-wsl/anaconda3/envs/tf_od/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n\n    TypeError: tf__distillation_loss() missing 1 required positional argument: 'teacher_preds'\n"
     ]
    }
   ],
   "source": [
    "train_student_model(teacher_model, student_model, train_data, val_data, epochs=10, learning_rate=0.001)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_od",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
